<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://stonezhng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://stonezhng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-12T18:55:16+00:00</updated><id>https://stonezhng.github.io/feed.xml</id><title type="html">blank</title><subtitle>Hi this is Sidong (or you can just call me Stone). I am recording my research projects, ideas and learning notes in this website. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Introduction to Normalizing Flows</title><link href="https://stonezhng.github.io/blog/2023/flows/" rel="alternate" type="text/html" title="Introduction to Normalizing Flows"/><published>2023-10-07T16:40:16+00:00</published><updated>2023-10-07T16:40:16+00:00</updated><id>https://stonezhng.github.io/blog/2023/flows</id><content type="html" xml:base="https://stonezhng.github.io/blog/2023/flows/"><![CDATA[<h1 id="basic-normalizing-flow">Basic Normalizing Flow</h1> <p>A <strong>normalizing flow</strong> is similar to a VAE in that we try to build up $p(X)$ by starting from a simple known distribution $p(Z)$. $X$ and $Z$ are of <strong>same dimensionality</strong>.</p> <p>The very basic idea of a flow connecting a complex $X$ and a simple $Z$ would be using a <strong>bijective</strong> function $f$ with its inverse $f^{-1}$ such that:</p> <ul> <li>$X = f(Z)$</li> <li>$Z = f^{-1}(X)$</li> <li>$p(X) = p_Z(f^{-1}(X))|\text{delta}(\mathbf{J}_{f^{-1}})|$ where the term on the right is the absolute value of the determinant of the Jacobian of $f^{-1}(X)$ w.r.t. $X$, and $p_Z$ uses a subscription $Z$ to differentiate it from the distribution of $X$.</li> </ul> <p>It is natural to introduce a chain structure between $X$ and $Z$:</p> <ul> <li>$X = f_1(f_0(Z))$</li> <li>$Z = f_0^{-1}(f_1^{-1}(X))$</li> <li>$p(X) = p_Z(f_0^{-1}(f_1^{-1}(X))) \left\lvert \text{delta}(\mathbf{J}<em>{f_0^{-1}}) \right\lvert \left\lvert \text{delta}(\mathbf{J}</em>{f_1^{-1}}) \left\right$</li> </ul> <h2 id="training-process">Training Process</h2> <p>Since most of the time $X$ is what we observed and has an empirical distribution consisting of $N$ data points ${X_1, X_2, \cdots, X_N}$, we can simply optimize the negative loglikelihood:</p> \[\text{argmin}_f \sum_{i = 1}^N -\log (p(X_I)) = \text{argmin}_f \sum_{i = 1}^N -\log (p_Z(f^{-1}(X_i))|\text{delta}(\mathbf{J}_{f^{-1}(X_i)})|)\] <h2 id="commonly-used-flows">Commonly Used Flows</h2> <h4 id="planar-flow">Planar Flow</h4> \[X=f(Z)= Z+ \mathbf{u} h(\mathbf{w}^TZ+b)\] <p>$\mathbf{u}, \mathbf{w}$ and $b$ are parameters. Additional constraints are required on $\mathbf{u}, \mathbf{w}, b$ and $h$ to guarantee the function is bijective. For example, it is ituitive that $h$ needs to be bijective, like $h = \tanh$.</p> <p>The Jabobian of $f^{-1}(X)$ is not obvious, as it depends on $h$, so the analytic form of $p(X)$ is not easy to compute.</p> <h3 id="nonlinear-independent-components-estimation-nice">Nonlinear Independent Components Estimation (NICE)</h3> <p>This method requires that $X$ can be split into two disjoint parts, $X_1$ and $X_2$, i.e. $X = [X_1, X_2]$. Same assumption for $Z$.</p> <p>Forward mapping $f: Z \rightarrow X$</p> <ul> <li>$X_1 = Z_1$</li> <li>$X_2 = Z_2 + m_\theta(Z_1)$, where $m_\theta$ is a neural network Inverse mapping $f^{-1}: X \rightarrow Z$</li> <li>$Z_1 = X_1$</li> <li>$Z_2 = X_2 - m_\theta(X_1)$ The inverse mapping of $Z_2$ can be simply obtained by replacing $Z_1$ in forward mapping of $X_2$ with $X_1$ and move $m_\theta(Z_1)$ (equivalent to $m_\theta(X_1)$) to LHS.</li> </ul> <p>The Jacobian of the forward mapping is lower trangular, whose determinant is simply the product of the elements on the diagonal, i.e.</p> \[\frac{\partial f^{-1}(X)}{\partial X} = \begin{pmatrix} \frac{\partial (Z_1)}{\partial X_1} &amp; \frac{\partial (Z_1)}{\partial X_2} \\ \frac{\partial (Z_2)}{\partial X_1} &amp; \frac{\partial (Z_2)}{\partial X_2} \end{pmatrix} =\begin{pmatrix} I &amp; 0 \\ \frac{\partial (-m_\theta(X_1))}{\partial X_1} &amp; I \end{pmatrix}\] \[\text{delta}(\begin{pmatrix} I &amp; 0 \\ \frac{\partial (-m_\theta(X_1))}{\partial X_1} &amp; I \end{pmatrix}) = 1\] <p>Therefore, this defines a volume preserving transformation.</p> <h1 id="continuous-normalizing-flows">Continuous Normalizing Flows</h1> <p><a href="https://browse.arxiv.org/pdf/1806.07366.pdf">Original paper</a></p> <p>Continuous Normalizing Flows solves the problem of selecting proper transition functions and the high computation complexity of Jacobians. The idea first origniates from a discrete sequence based transition:</p> \[X_{t+1} = X_t + f(X_t, \theta_t)\] <p>where $f$ is time-sensitive with the parameter $\theta_t$ changing with time. From a perspective of flows, this sequence transition provides a natural way of connecting $X$ and $Z$, i.e. $X$ being $X_T$ at the end of the sequence and $Z$ being $X_0$ at the beginning of the sequence, with finite discrete intermediate states $X_t, t \in [1, T-1] \cap \mathbb{N}^+$. The transition is obviously bijective, since each step is a simple linear function.</p> <p>We then want to see what if the sequence becomes continous. Since the discrete sequence transition is describing the change at time $t$ in a discrete manor, i.e. $X_{t+1} - X_t = \Delta X_{t} =f(X_t, \theta_t)$, the continous version is then: \(\frac{\partial X_t}{\partial t} = f(X_t, t, \theta)\) which is an ordinary differential equation (ODE). Starting from the input layer$X_0$ ($Z$), we can define the output layer$X_T$ to be the solution to this ODE initial value problem at some time $T$ and emprically computed by some black box ODE solver:</p> \[X_t = X_0 + \int_0^tf(X_i, i, \theta)di = \text{ODESolve}(X_0, f, 0, t, θ)\] <h2 id="computation-of-jacobian">Computation of Jacobian</h2> <p>With the ODE to define the continous mapping from $X_t$ to $X_{t+1}$, the next question is how the probablity would change from $t$ to $t+1$. In the discrete case, we have</p> <table> <tbody> <tr> <td>$$\log (p(X_{t+1})) - \log(p(X_t)) = \log(</td> <td>\text{delta}(\mathbf{J}_{F_t^{-1}})</td> <td>)$$ ,</td> </tr> </tbody> </table> <p>where $F_t$ is the mapping function at time $t$: $X_{t+1} = X_{t} + \int_t^{t+1}f(X_i, i, \theta)di = \text{ODESolve}(X_t, f, t, t+1, θ)$.</p> <p>The paper proved that in the continous case,</p> \[\frac{\partial \log(p(X_t))}{\partial t} = -\text{tr}(\frac{\partial f}{\partial X_t})\] <p>with same $f$ defined in the ODE $\frac{\partial X_t}{\partial t} = f(X_t, t, \theta)$. ($f$ is of the same dimensionality as $X_t$ so its first derivative w.r.t $X_t$ is a square matrix, and this theorem says we can only compute the diagnal elements and sum them up)</p> <p>An example made by the author is a continous version of Planar Flow, where the function $\mathbf{u}h(\cdot)$ is not served as a direct mapping from $X_t$ to $X_{t+1}$, but describing the gradient (dynamic) at $X_t$:</p> \[\frac{\partial X_t}{\partial t} = \mathbf{u}h(\mathbf{w}^TX_t + b)\] \[\frac{\partial \log(p(X_t))}{\partial t} = -\mathbf{u}^T\frac{\partial h}{\partial X_t}\] <p>The two ODEs then give way of sampling complex $X$ ($X_t$)from simple random variable $Z$ ($X_0$) by the first ODE and estimate its density by the second ODE, assuming we have a good black box ODE solver.</p> <p>The author did two addtional things to the two ODEs.</p> <ul> <li>Because the trace function is linear, we can easily add multiple $f$s to ODE:</li> </ul> \[\frac{\partial X_t}{\partial t} = \sum_{i=1}^N f_i(X_t, t, \theta)\] \[\frac{\partial \log(p(X_t))}{\partial t} = \sum_{i=1}^N-\text{tr}(\frac{\partial f_i}{\partial X_t})\] <ul> <li>Also by utilizing the linearity, we can specify the role of $t$ in $f$ in a gating mechanism manner:</li> </ul> \[\frac{\partial X_t}{\partial t} = \sum_{i=1}^N \sigma_i(t)f_i(X_t, \theta)\] \[\frac{\partial \log(p(X_t))}{\partial t} = \sum_{i=1}^N-\text{tr}(\sigma_i(t)\frac{\partial f_i}{\partial X_t})\] <p>where $f_i$ now is independent of $t$</p> <h2 id="backpropogation">Backpropogation</h2> <p>A vanilla way of computing the gradients of all $f$ is expensive. The author proposed using the adjoint sensitivity method, which computes gradients by solving a second, augmented ODE backwards in time, and is applicable to all ODE solvers.</p> <p>Suppose we have a scalar loss function $L$ on the output $X_{t_1} = \text{ODESolve}(X_{t_0}, f, t_0, t_1, θ)$, written as \(L(\text{ODESolve}(X_{t_0}, f, t_0, t_1, θ))\)The target is $\frac{\partial L}{\partial \theta}$.</p> <p>We first work on the adjoint \(\mathbf{a}(t) = \frac{\partial L}{\partial X_{t}}\)Its gradients (dynamics) are given by another ODE, which can be thought of as the instantaneous analog of the chain rule:</p> \[\frac{\partial \mathbf{a}(t)}{\partial t} = -\mathbf{a(t)}^T\frac{\partial f(X_t, t, \theta)}{\partial X_{t}}\] <p>We can then compute $\mathbf{a}(t)$ by another call to an ODE solver. This solver <strong>must run backwards,</strong> starting from the initial value of $\mathbf{a}(t_1)$. Because we need to know $X_t$ when computing this gradient at time $t$, we need to reversely get $X_t$ starting from $t_1$ together with the backward computation of $\mathbf{a}(t)$.</p> <p>Finally we use $\mathbf{a}(t)$ to compute $\frac{\partial L}{\partial \theta}$:</p> \[\frac{\partial L}{\partial \theta} = -\int_{t_0}^{t_1}\mathbf{a}(t)^T\frac{\partial f(X_t, t, \theta)}{\partial \theta} dt\] <p>which is another ODE:</p> \[\frac{\partial \frac{\partial L}{\partial \theta}}{\partial t} = -\mathbf{a}(t)^T\frac{\partial f(X_t, t, \theta)}{\partial \theta}\] <p>so call ODESolver again.</p> <h1 id="riemannian-continuous-normalizing-flows">Riemannian Continuous Normalizing Flows</h1> <p><a href="https://proceedings.neurips.cc/paper/2020/file/1aa3d9c6ce672447e1e5d0f1b5207e85-Paper.pdf">Original paper</a></p> <p>This work heavliy relies on the understanding of topology so I add an additional background section.</p> <p>In this work, flows are defined via vector fields on manifolds and computed as the solution to the associated ordinary differential equation (ODE). Intuitively, this method operates by first parametrizing a vector field on the manifold with a neural network, then sampling particles from a base distribution, and finally approximating their flow along the vector field using a numerical solver. The high level idea is, for the ODE of the dynamic: \(\frac{\partial X_t}{\partial t} = f(X_t, t, \theta)\) We are now considering $f(X_t, t, \theta)$ as a vector field, and it is describing the velocity at $X_t$. Consider the temporal evolution of a particle $X_t$ on a $d$-dimensional manifold $\mathcal{M}$, whose velocity is given by a vector field $f(X_t, t, \theta)$. Intuitively,$f(X_t, t, \theta)$) indicates the direction and speed along which the particle is moving on the manifold’s surface. Classic examples for such vector fields include weathercocks giving wind direction and compasses pointing toward the magnetic north pole of the earth.</p> <h2 id="geometric-backgrounds">Geometric Backgrounds</h2> <p>Mostly based on <a href="https://www.cis.upenn.edu/~cis6100/cis61005sl7.pdf">this</a></p> <h3 id="mainfold">Mainfold</h3> <p>It is a topological space that can be covered by a collection of open subsets, $\mathbb{U}<em>\alpha$, where each $\mathbb{U}</em>\alpha$ is isomorphic to some “standard model”, e.g., some open subset of Euclidean space, $\mathbb{R}^n$. (an isomorphism is a structure-preserving mapping between two structures of the same type that can be reversed by an inverse mapping )</p> <h3 id="chart">Chart</h3> <p>Given a topological space, $\mathcal{M}$, a chart (or <strong>local coordinate map</strong>) is a pair, $(\mathbb{U}, \varphi)$, where $\mathbb{U}$ is an open subset of $\mathcal{M}$ and $\varphi: \mathbb{U} \rightarrow \mathbb{\Omega}$ is a homeomorphism onto an open subset, $\mathbb{\Omega} = \varphi(\mathbb{U})$, of $\mathbb{R}^{n_\phi}$ (for some $n_\phi \ge 1$).</p> <p>( <strong>homeomorphism</strong> (from <a href="https://en.wikipedia.org/wiki/Greek_language" title="Greek language">Greek</a> <a href="https://en.wiktionary.org/wiki/%E1%BD%85%CE%BC%CE%BF%CE%B9%CE%BF%CF%82" title="wikt:ὅμοιος">ὅμοιος</a> <em>(homoios)</em> ’similar, same’, and <a href="https://en.wiktionary.org/wiki/%CE%BC%CE%BF%CF%81%CF%86%CE%AE" title="wikt:μορφή">μορφή</a> <em>(morphē)</em> ’shape, form’, named by Henri Poincaré, also called <strong>topological isomorphism</strong>, or <strong>bicontinuous function</strong>, is a bijective and continuous function between topological spaces that has a continuous inverse function.)</p> <p>A more ituitive way of describing a chart is found <a href="https://en.wikipedia.org/wiki/Atlas_(topology)">here</a>: A <strong>chart</strong> for a topological space $\mathcal{M}$ (also called a <strong>coordinate chart</strong>, <strong>coordinate patch</strong>, <strong>coordinate map</strong>, or <strong>local frame</strong>) is a homeomorphism  $\varphi$  from an open subset $\mathbb{U}$ of $\mathcal{M}$ to an open subset of a <strong>Euclidean space</strong>. The chart is traditionally recorded as the ordered pair $(\mathbb{U}, \varphi)$.</p> <p>For a point $p \in \mathbb{U}$ , we obtain its <strong>local coordinates</strong> by first mapping $p$ to Euclidean space via $\varphi$, i.e. $\varphi(p)$, then you do projection to $n_\varphi$ coordinates in this Euclidean space. The coordinates can be written as $(\text{Proj}(\varphi(p))<em>1, \text{Proj}(\varphi(p))_2, \cdots, \text{Proj}(\varphi(p))</em>{n_\varphi})$</p> <h3 id="atlas">Atlas</h3> <p>Not that god in Greek myth.</p> <p>An atlas of $\mathcal{M}$ consists of individual charts that, roughly speaking, describe individual regions of the manifold. Formally, it is an index family ${(\mathbb{U}<em>\alpha, \varphi</em>\alpha): \alpha \in \text{Some set} }$ which covers $\mathcal{M}$, i.e. $\cup_\alpha \mathbb{U}_\alpha = \mathcal{M}$.</p> <h3 id="transition-map">Transition Map</h3> <p>A transition map provides a way of comparing two charts of an atlas. To make this comparison, we consider the composition of one chart with the inverse of the other. Suppose $(\mathbb{U}<em>\alpha, \varphi</em>\alpha)$ and $(\mathbb{U}<em>\beta, \varphi</em>\beta)$ are two charts for $\mathcal{M}$ such that $\mathbb{U}<em>\alpha \cap \mathbb{U}</em>\beta$ is not empty. The transition map $\tau_{\alpha, \beta}: \varphi_\alpha(\mathbb{U}<em>\alpha \cap \mathbb{U}</em>\beta) \rightarrow \varphi_\beta(\mathbb{U}<em>\alpha \cap \mathbb{U}</em>\beta)$ (map the $\varphi_\alpha$ based Euclidean of the joint part to $\varphi_\beta$ based Euclidean of the joint part) is defined as: $\tau_{\alpha, \beta} = \varphi_\beta \circ \varphi_\alpha^{-1}$. With $\tau_{\alpha, \beta}$ you can directly jump from $\varphi_\alpha$ based Euclidean to $\varphi_\beta$ based Euclidean on the joint area of the two charts. Note that we can define in the same way a jump from $\varphi_\beta$ to $\varphi_\alpha$ as $\tau_{\beta, \alpha}: \varphi_\beta(\mathbb{U}<em>\alpha \cap \mathbb{U}</em>\beta) \rightarrow \varphi_\alpha(\mathbb{U}<em>\alpha \cap \mathbb{U}</em>\beta)$, $\tau_{\beta, \alpha} = \varphi_\alpha \circ \varphi_\beta ^{-1}$, so the transition map always come in pairs.</p> <h3 id="ck-n-atlas">$C^k$ n-atlas</h3> <p>A family of charts that</p> <ul> <li>Covers the whole mainfold $\mathcal{M}$, $\cup_\alpha \mathbb{U}_\alpha = \mathcal{M}$</li> <li>Every chart projects to Euclidean of the same dimension $n$, $\varphi_i(p_i) \in \mathbb{R}^n \forall i$</li> <li>Whenever $\mathbb{U}<em>i \cap \mathbb{U}_j \ne \Phi$, the transition map $\tau</em>{i, j}$ is a $C^k$ -diffeomorphism (k times differentiable)</li> </ul> <h3 id="compatible">Compatible</h3> <p>Chart $(\mathbb{U}, \varphi)$ is compatible with $C^k$ n-atlas $\mathcal{A}$ iff for every $\mathbb{U}_i \in \text{Charts of }\mathcal{A}$ and $\mathbb{U}_i \cap \mathbb{U} \ne \Phi$ , the transition maps between the two are both $C^k$ -diffeomorphism.</p> <p>Two altases are $C^k$ compatible iff every chart of one is compatible with the other atlas. This is equivalent to saying that the union of the two $C^k$ atlases is still a $C^k$ atlas.</p> <p>An atlas $\mathcal{A}$ is maximal if it contains <em>all possible</em>  $C^k$ compatible atlases. The definition of a maximal atlas is needed so that two <strong>manifolds</strong> with different atlases, but which are $C^K$-compatible will not be considered different manifolds. A maximal $C^K$ atlas is what we call a $C^K$ differentiable structure. <a href="https://math.stackexchange.com/questions/1388864/i-am-confused-by-the-different-definitions-of-manifolds">source</a></p> <h3 id="ck-manifold-of-dimension-n">$C^k$ manifold of dimension n</h3> <p>A manifold $\mathcal{M}$ of dimension $n$ with a maximal $C^k$ atlas on it.</p> <h3 id="tangent-space">Tangent Space</h3> <p>For a $d$-dimensional manifold $\mathcal{M}$, at every point $p$ on $\mathcal{M}$ there is a tagent space $\mathcal{T}_p \mathcal{M}$.</p>]]></content><author><name></name></author><category term="math"/><category term="math,"/><category term="flows,"/><category term="deep"/><category term="learning"/><summary type="html"><![CDATA[Basic Normalizing Flow]]></summary></entry><entry><title type="html">Generalized funtions</title><link href="https://stonezhng.github.io/blog/2021/generalized-function/" rel="alternate" type="text/html" title="Generalized funtions"/><published>2021-03-28T18:00:00+00:00</published><updated>2021-03-28T18:00:00+00:00</updated><id>https://stonezhng.github.io/blog/2021/generalized-function</id><content type="html" xml:base="https://stonezhng.github.io/blog/2021/generalized-function/"><![CDATA[<h1 id="functional"><strong>Functional</strong></h1> <p><a href="https://mathworld.wolfram.com/Functional.html">Functional</a> refers to a mapping from a space $\mathit{X}$ (usually of functions) into $\boldsymbol{R}$ (real numbers). (Or complex numbers, in a more general case.)</p> <h1 id="generalized-function"><strong>Generalized Function</strong></h1> <h2 id="definition">Definition</h2> <p>Let \(\varphi(x)\) be an <em>argument of the function</em>, which is a function where $x \in \boldsymbol{R}$, and $\forall x$, $\varphi(x) \in \mathscr{D}$.</p> <ul> <li> <p>$\varphi(x)$ is <em>smooth</em>, if it has derivatives of all orders.</p> </li> <li> <p>$\varphi(x)$ is <em>compact</em>, if it has a bounded <em>support</em>. The <em>support</em> of a function $\varphi(x)$ is written as $\text{supp}(\varphi)$, $\text{supp}(\varphi) := \{x \in \mathit{X} \mid \varphi(x) \ne 0 \}$.</p> </li> </ul> <p>Let $f(x) := \boldsymbol{R} \rightarrow \boldsymbol{R}$ be the kernel of $\varphi(x)$.</p> <p>We have the following <a href="https://mathworld.wolfram.com/LinearFunctional.html"><em>linear functional</em></a>:</p> \[T[\varphi] = \int f(x) \varphi(x) dx\] <ul> <li> <p>$T[\cdot]$ is <em>continuous</em>, if for any sequence $\{\varphi_k\}_{k = 1, \cdots, \infty}$, when the sequence converges to $\varphi$ at $k \rightarrow \infty$, the corresponding sequence $\{T[\varphi_k]\}$ converges to $T[\varphi]$.</p> </li> <li> <p>$T[\cdot]$ maps inputs from $\mathscr{D}$ (function space) to $\boldsymbol{R}$.</p> </li> </ul> <p><span style="color: green"> Any <em>linear functional</em> $T[\varphi]$, which is <em>continuous</em> on the set $\mathscr{D}$ of <em>smooth compact functions</em>, is called a <em>generalized function</em>. A <em>generalized function</em> is a <em>linear functional</em>, but not a <em>function</em>. </span></p> <h2 id="linearity-of-generalized-function">Linearity of Generalized Function</h2> <p>$\forall \varphi(x), \psi(x) \in \mathscr{D}$, $\forall a, b \in \boldsymbol{R}$, we have:</p> \[T[a\varphi + b\psi] = a T[\varphi] + b T[\psi]\] <h2 id="regular-generalized-function">Regular Generalized Function</h2> <p>If the kernal $f(x)$ is an everywhere continuous, bounded function, $T[\varphi]$ is called a <em>regular generalized function</em> identified with the kernal $f(x)$.</p> <h2 id="singular-generalized-function">Singular Generalized Function</h2> <p>A <em>singular generlized function</em> $T[\varphi]$ is still linear continuous, but its kernel is not continuous.</p> <p>The most important example is the function:</p> \[T[\varphi] = \varphi(0)\] <p>Though the kernel is not continuous, we still give it a symbol $\delta(x)$ and write it as:</p> \[T[\varphi] = \int \delta(x) \varphi(x) dx = \varphi(0)\] <p>Although the above thing is well known as the delta function, according to <a href="https://en.wikipedia.org/wiki/Dirac_delta_function">Wikipedia</a> and <a href="https://mathworld.wolfram.com/DeltaFunction.html">Wolfram</a>, given different contexts, the delta function can refer to different things. As a distribution, the delta function is $T[\cdot]$, the linear functional, and is written as $\delta[\varphi] = \varphi(0)$. As a measure, or in the engineering context, the kernel $\delta(x)$ in $\int \delta(x) \varphi(x) dx$ is the delta function. A very confusing expression is:</p> \[\delta [\varphi] = \int \delta(x) \varphi(x) dx = \varphi(0)\] <p>If $\varphi(x) = 1$:</p> \[\delta [1] = \int \delta(x) dx = 1\] <p>We can also “shift” the delta function to map the function space to function value at arbitrary points: (again the first $\delta_a$ is a functional delta, the second $\delta$ in the integral is a function delta)</p> \[\delta_a [\varphi] = \int \delta(x - a) \varphi(x) dx = \varphi(a)\] <p>One approach to estimate the delta function is by the limit of a sequence of ordinary integrals, where the $k$ th element in the sequence looks like:</p> \[\delta_k [\varphi] = \int \delta_k(x) \varphi(x) dx\] <p>$\delta_k(x)$ can be ordinary functions. One choice is the Gaussian probability density function: $\delta_k(x) = \frac{1}{k\sqrt{2 \pi}} e^{-\frac{x^2}{2k^2}}$</p> <h1 id="derivatives-of-generalized-function">Derivatives of Generalized Function</h1> <p>We define the derivative of a generalized function by the derivative of its kernel functions:</p> \[T'[\varphi] = \int f'(x) \varphi(x) dx\] <p>According to the rule of integration by parts, we have:</p> \[\int f'(x) \varphi(x) dx + \int f(x) \varphi'(x) dx = f(x)\varphi(x) |_{-\infty}^{\infty}\] <p>Recall that $\varphi(x)$ is compact (has a bounded support), so $\lim_{x \rightarrow \infty}\varphi(x) = 0$, $\lim_{x \rightarrow -\infty}\varphi(x) = 0$, therefore we have:</p> \[\int f'(x) \varphi(x) dx + \int f(x) \varphi'(x) dx = 0\] <p>Which means:</p> \[T'[\varphi] + T[\varphi'] = 0\] <p>So We can do derivative on $\varphi$ to get the derivative of a generalized function.</p> <p>With the same logic, we have</p> \[T^{(n)}[\varphi] = (-1)^nT[\varphi^{(n)}(x)]\] <p>The Leibniz formula also works on the product of a generalized function and a function. First we have the product of a function and a generalized function defined as:</p> \[g(x)T[\varphi] = T[g\varphi]\] <p>Then the Leibniz formula is:</p> \[(g(x)T[\varphi])' = g'(x)T[\varphi] + g(x)T'[\varphi]\] \[(g(x)T[\varphi])^{(n)} = \sum^{n}_{m = 0}g^{(m)}(x)T^{(n-m)}[\varphi]\] <p>This is more like a trick, since the symbol $g’(x)T[\varphi]$ is not an actual product, you just switch between different expressions to make it look like the Leibniz formula :</p> \[\begin{align*} (g(x)T[\varphi])' &amp;= T'[g\varphi] \\ &amp;= T[(g\varphi)'] \\ &amp;= T[g'\varphi + g\varphi'] \\ &amp;= T[g'\varphi] + T[g\varphi'] \text{ (linearity)} \\ &amp;= g'(x)T[\varphi] + g(x)T'[\varphi] \end{align*}\] <h1 id="generalized-function-of-a-composite-argument">Generalized Function of a Composite Argument</h1> <p>First we have the following equality:</p> \[\int f(g(x))\varphi(x) dx = \int f(y)\varphi(g^{-1}(y)) g^{-1 \prime} (y) dy\] <p>Where $g^{-1}(x)$ is the inverse of $g(x)$, i.e. $g(g^{-1}(x)) = x$. The above equality can be easily proved by replace $x$ on the left side with $g^{-1}(y)$.</p> <p>We name $\int f(g(x))\varphi(x) dx$ as a generalized function $T$ of a <em>composite argument</em> $g(x)$.</p>]]></content><author><name></name></author><category term="math"/><category term="math,"/><category term="algebra"/><summary type="html"><![CDATA[Functional]]></summary></entry><entry><title type="html">Pytorch Adam may update frozen parameters</title><link href="https://stonezhng.github.io/blog/2021/adam-may-update-frozen-param/" rel="alternate" type="text/html" title="Pytorch Adam may update frozen parameters"/><published>2021-03-25T20:12:00+00:00</published><updated>2021-03-25T20:12:00+00:00</updated><id>https://stonezhng.github.io/blog/2021/adam-may-update-frozen-param</id><content type="html" xml:base="https://stonezhng.github.io/blog/2021/adam-may-update-frozen-param/"><![CDATA[<p>I was working on a deep learning training task that needed to freeze part of the parameters after 10 epochs of training. With Adam optimizer, even if I set</p> <pre><code class="language-Python">for parameter in model:
    parameter.requires_grad = False
</code></pre> <p>There are still trivial differences before and after each epoch of training on those frozen parameters, like one can be from 0.1678 to 0.1674.</p> <p>According to <a href="https://discuss.pytorch.org/t/why-is-it-when-i-call-require-grad-false-on-all-my-params-my-weights-in-the-network-would-still-update/22126/15">this post</a>, Pytorch indeed has such an issue.</p> <p>A better practice is to split the training process into two parts like a pretraining-fine tuing work. In my situation,</p> <ul> <li>in the first part, train all the parameters and save them; (pretraining)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="bp">...</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="bp">...</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="p">...)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">checkpoint_path</span><span class="p">)</span>

<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="nf">need_freeze</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div> <ul> <li>in the second part, reinitiate the model, start with a new optimizer without the frozen parameters, load the trained parameters; (fine tuning)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>

<span class="sh">"""</span><span class="s">
load saved model dict
</span><span class="sh">"""</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="bp">...</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="bp">...</span>

<span class="n">filtered_params</span> <span class="o">=</span>  <span class="nf">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">filtered_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="p">...)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">TOTAL_NUM</span> <span class="o">-</span> <span class="mi">10</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">checkpoint_path</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>to check if the parameters are indeed not updated:</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="bp">...</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="bp">...</span>

<span class="n">filtered_params</span> <span class="o">=</span>  <span class="nf">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">filtered_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="p">...)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">TOTAL_NUM</span> <span class="o">-</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">freeze_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="nf">need_freeze</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span>

    <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>

    <span class="n">updated_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="nf">need_freeze</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">freeze_params</span><span class="p">)):</span>
        <span class="n">eq_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="n">freeze_params</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">updated_params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">assert</span> <span class="n">eq_tensor</span><span class="p">.</span><span class="nf">all</span><span class="p">().</span><span class="n">data</span>


<span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="n">checkpoint_path</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="coding"/><category term="deep"/><category term="learning,"/><category term="Pytorch"/><summary type="html"><![CDATA[I was working on a deep learning training task that needed to freeze part of the parameters after 10 epochs of training. With Adam optimizer, even if I set]]></summary></entry><entry><title type="html">Jekyll Installation on macOS Catalina</title><link href="https://stonezhng.github.io/blog/2021/jekyll-installation-on-macos/" rel="alternate" type="text/html" title="Jekyll Installation on macOS Catalina"/><published>2021-03-23T02:43:12+00:00</published><updated>2021-03-23T02:43:12+00:00</updated><id>https://stonezhng.github.io/blog/2021/jekyll-installation-on-macos</id><content type="html" xml:base="https://stonezhng.github.io/blog/2021/jekyll-installation-on-macos/"><![CDATA[<p>Due to new security features in macOS Mojave and later, the <a href="https://jekyllrb.com/docs/installation/macos/">tutorial on Jekyll website</a> will raise an error when running command: <code class="language-plaintext highlighter-rouge">gem install &lt;PACKAGE&gt;</code>:</p> <div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">ERROR:  Loading command: install (LoadError)
    cannot load such file -- openssl
ERROR:  While executing gem ... (NoMethodError)
    undefined method `invoke_with_build_args' for nil:NilClass
</span></code></pre></div></div> <p>The solution is to reinstall ruby with openssl, as discussed in <a href="https://github.com/rvm/rvm/issues/4819">this thread</a>:</p> <ul> <li>Step 1: install openssl: <code class="language-plaintext highlighter-rouge">brew install rbenv/tap/openssl@1.0</code></li> <li>Step 2: install/reinstall ruby with openssl: <code class="language-plaintext highlighter-rouge">rvm install &lt;RUBY_VERSION&gt; --with-openssl-dir='/usr/local/opt/openssl@1.0'</code> (if reinstall, replace <code class="language-plaintext highlighter-rouge">install</code> with <code class="language-plaintext highlighter-rouge">reinstall</code>)</li> <li>Step 3: update gem: <code class="language-plaintext highlighter-rouge">gem update --system</code></li> </ul> <p>You are good to go! Have fun with gem!</p>]]></content><author><name></name></author><category term="coding"/><category term="jekyll"/><category term="macOS"/><summary type="html"><![CDATA[Due to new security features in macOS Mojave and later, the tutorial on Jekyll website will raise an error when running command: gem install &lt;PACKAGE&gt;:]]></summary></entry></feed>